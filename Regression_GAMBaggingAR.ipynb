{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5b0b29-f218-42be-ad49-250258fa3f5c",
   "metadata": {},
   "source": [
    "On rajoute les données meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ade40bd-d76a-496b-a920-9cf77202eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46710d7f-b791-41d9-8e44-3e5b41f8d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_debit = pd.read_csv(\"../Data/Base/Stations_Debit.csv\")\n",
    "liste_stations_debit = list(stations_debit[\"Code station\"])\n",
    "\n",
    "mesures_train_X = pd.read_csv(\"../Data/Base/Mesures_Train_X.csv\")\n",
    "mesures_train_X[\"Date\"] = pd.to_datetime(mesures_train_X[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")\n",
    "mesures_train_Y = pd.read_csv(\"../Data/Base/Mesures_Train_Y.csv\")\n",
    "mesures_train_Y[\"Date\"] = pd.to_datetime(mesures_train_Y[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "train_split_X = pd.read_csv(\"../Data/Base/Index_CV_X.csv\")\n",
    "train_split_Y = pd.read_csv(\"../Data/Base/Index_CV_Y.csv\")\n",
    "\n",
    "mesures_test_X = pd.read_csv(\"../Data/Base/Mesures_Test_X.csv\")\n",
    "mesures_test_X[\"Date\"] = pd.to_datetime(mesures_test_X[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")\n",
    "mesures_test_Y = pd.read_csv(\"../Data/Base/Mesures_Test_Y.csv\")\n",
    "mesures_test_Y[\"Date\"] = pd.to_datetime(mesures_test_Y[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8752eee-0b85-4a1f-9781-d7b6d3d9e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_meteo = pd.read_csv(\"../Data/Base/Stations_Meteo.csv\")\n",
    "liste_stations_meteo = list(stations_meteo[\"ID\"].apply(lambda x: str(x).rjust(5, \"0\")))\n",
    "colonnes_meteo = [\"Pression\", \"Vent_Nord\", \"Vent_Est\", \"Vitesse_vent\", \"Temperature\", \"Humidite\", \"Precipitations\"]\n",
    "tempo = []\n",
    "for code in liste_stations_meteo:\n",
    "    tempo += [tp + \"_\" + code for tp in colonnes_meteo]\n",
    "colonnes_meteo_stations = tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9732a271-7af8-4f7c-8840-2dcbbb4bb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Eval_fcts.py\n",
    "%run Standardize_fcts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c90c5f1-b157-46a8-b3cc-8034f8195fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Regression_GAM_Gamma.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b81e78-551c-47ca-9e0b-ebd3d94d52ea",
   "metadata": {},
   "source": [
    "# Val croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb59d54-eebd-4184-8065-200bd98d1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_knots = 10\n",
    "lr = 3\n",
    "max_lag = 7\n",
    "\n",
    "curr_alpha=3\n",
    "curr_compo=10\n",
    "curr_feature=\"log2\"\n",
    "curr_sample=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbd14f45-0ebd-45df-83df-cd71c897e2a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/9 [00:25<?, ?it/s]\u001b[A\n",
      "  0%|                                                     | 0/1 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2964/3354109340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m               y = curr_train_X_standard_residus[code])\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m#reg2.fit(X = curr_train_X_standard_residus[colonnes_reg], Y = curr_train_X_standard_residus[code])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             reg2.fit(X = curr_train_X_standard_residus[colonnes_reg],\n\u001b[0m\u001b[1;32m     84\u001b[0m               y = curr_train_X_standard_residus[code])\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m#reg3.fit(X = curr_train_X_standard_residus[colonnes_reg],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for curr_lag in tqdm(range(max_lag,max_lag+1)):\n",
    "    cv_scores_RMSE_standard = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "    cv_scores_MAE_standard = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "    cv_scores_R2_standard = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "\n",
    "    cv_scores_RMSE = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "    cv_scores_MAE = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "    cv_scores_R2 = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "\n",
    "    for curr_split in tqdm(range(9)):\n",
    "\n",
    "        # Donnees\n",
    "        curr_train_X = mesures_train_X[train_split_X[\"Train_\" + str(curr_split)]]\n",
    "        curr_train_Y = mesures_train_Y[train_split_Y[\"Train_\" + str(curr_split)]]\n",
    "        curr_test_X = mesures_train_X[train_split_X[\"Test_\" + str(curr_split)]]\n",
    "        curr_test_Y = mesures_train_Y[train_split_Y[\"Test_\" + str(curr_split)]]\n",
    "        liste_dates = curr_test_Y[\"Date\"]\n",
    "\n",
    "        curr_train_X_mean = curr_train_X[liste_stations_debit + colonnes_meteo_stations].mean()\n",
    "        for code in liste_stations_debit:\n",
    "            curr_train_X_mean[code] = 0\n",
    "        curr_train_X_std = curr_train_X[liste_stations_debit + colonnes_meteo_stations].std()\n",
    "        curr_train_X_standard = fct_Standardize(curr_train_X, curr_train_X_mean,\n",
    "                                                curr_train_X_std, liste_stations_debit + colonnes_meteo_stations)\n",
    "        curr_train_X_standard[\"Date\"] = curr_train_X[\"Date\"]\n",
    "        #GAM\n",
    "        spline_fit = fct_Regression_SplineGamma_fit(curr_train_X_standard, liste_stations_debit, n_knots)\n",
    "        curr_train_X_standard_residus = fct_Regression_SplineGamma_residus(spline_fit, \n",
    "                                                                           curr_train_X_standard, \n",
    "                                                                           liste_stations_debit)\n",
    "        curr_train_X_standard_residus = pd.concat([curr_train_X_standard_residus, \n",
    "                                                      curr_train_X_standard[colonnes_meteo_stations]],\n",
    "                                                     axis = 1)\n",
    "\n",
    "         # Ajout AR\n",
    "        colonnes_reg = colonnes_meteo_stations\n",
    "        for i in range(curr_lag+1):\n",
    "            variable = curr_train_X_standard_residus[liste_stations_debit].shift(i+7)\n",
    "            variable.columns = [code+\"_\"+str(i) for code in liste_stations_debit]\n",
    "            curr_train_X_standard_residus = pd.concat([curr_train_X_standard_residus, variable], axis = 1)\n",
    "            colonnes_reg = colonnes_reg + [code+\"_\"+str(i) for code in liste_stations_debit]\n",
    "        curr_train_X_standard_residus = curr_train_X_standard_residus[(7+curr_lag):]\n",
    "\n",
    "        curr_test_X_standard =fct_Standardize(curr_test_X, curr_train_X_mean,\n",
    "                                              curr_train_X_std, liste_stations_debit + colonnes_meteo_stations)\n",
    "        curr_test_X_standard[\"Date\"] = curr_test_X[\"Date\"].values\n",
    "        curr_test_X_standard_residus = fct_Regression_SplineGamma_residus(spline_fit,\n",
    "                                                                          curr_test_X_standard, \n",
    "                                                                          liste_stations_debit)\n",
    "        curr_test_X_standard_residus = pd.concat([curr_test_X_standard_residus, \n",
    "                                                  curr_test_X_standard[colonnes_meteo_stations]],\n",
    "                                                 axis = 1)\n",
    "        # Ajout variables AR\n",
    "        for i in range(curr_lag+1):\n",
    "            variable = curr_test_X_standard_residus[liste_stations_debit].shift(i+7)\n",
    "            variable.columns = [code+\"_\"+str(i) for code in liste_stations_debit]\n",
    "            curr_test_X_standard_residus = pd.concat([curr_test_X_standard_residus, variable], axis = 1)\n",
    "        curr_test_X_standard_residus = curr_test_X_standard_residus[(7+curr_lag):]\n",
    "\n",
    "        curr_test_Y_standard = fct_Standardize(curr_test_Y, curr_train_X_mean,\n",
    "                                                curr_train_X_std, liste_stations_debit)\n",
    "        curr_test_Y_standard[\"Date\"] = curr_test_Y[\"Date\"]\n",
    "\n",
    "        curr_RMSE_standard = []\n",
    "        curr_MAE_standard = []\n",
    "        curr_R2_standard = []\n",
    "        curr_RMSE = []\n",
    "        curr_MAE = []\n",
    "        curr_R2 = []\n",
    "\n",
    "        for code in liste_stations_debit:\n",
    "\n",
    "            # Entrainement\n",
    "            reg1 = linear_model.Lasso(alpha = curr_alpha/1000, max_iter = 30000)\n",
    "            #reg2 = PLSRegression(n_components=curr_compo)\n",
    "            reg2 = RandomForestRegressor(max_features=curr_feature,\n",
    "                                            max_samples=curr_sample/10)\n",
    "            #reg3 = GradientBoostingRegressor(learning_rate = lr)\n",
    "            \n",
    "            reg1.fit(X = curr_train_X_standard_residus[colonnes_reg],\n",
    "              y = curr_train_X_standard_residus[code])\n",
    "            #reg2.fit(X = curr_train_X_standard_residus[colonnes_reg], Y = curr_train_X_standard_residus[code])\n",
    "            reg2.fit(X = curr_train_X_standard_residus[colonnes_reg],\n",
    "              y = curr_train_X_standard_residus[code])\n",
    "            #reg3.fit(X = curr_train_X_standard_residus[colonnes_reg],\n",
    "              #y = curr_train_X_standard_residus[code])\n",
    "            \n",
    "            #model = VotingRegressor([(\"LASSO\", reg1), (\"PLS\", reg2), (\"RF\", reg3)])\n",
    "            model = VotingRegressor([(\"LASSO\", reg1), (\"Random Forest\", reg2)])\n",
    "            model.fit(X= curr_train_X_standard_residus[colonnes_reg], y = curr_train_X_standard_residus[code])\n",
    "\n",
    "\n",
    "\n",
    "            # Predictions Standard\n",
    "            predictions_Y_standard_residus = model.predict(curr_test_X_standard_residus[colonnes_reg])\n",
    "            predictions_Y_standard_residus = pd.DataFrame(predictions_Y_standard_residus, columns=[code])\n",
    "            predictions_Y_standard_residus[\"Date\"] = curr_test_X_standard_residus[\"Date\"].values\n",
    "            # Filtre sur les dates\n",
    "            resultat = pd.DataFrame()\n",
    "            for curr_date in liste_dates:\n",
    "                resultat = pd.concat([resultat, predictions_Y_standard_residus[predictions_Y_standard_residus[\"Date\"] == curr_date]])\n",
    "            resultat = resultat.sort_values(by = \"Date\")\n",
    "            predictions_Y_standard_residus = resultat.copy()\n",
    "            # On rajoute la compo saisonnalité\n",
    "            predictions_Y_standard_saisonnalite = fct_Regression_SplineGamma_predict(spline_fit, liste_dates, [code])\n",
    "            predictions_Y_standard = predictions_Y_standard_residus[[\"Date\"]].copy()\n",
    "            predictions_Y_standard[code] = predictions_Y_standard_residus[code].values + predictions_Y_standard_saisonnalite[code].values\n",
    "\n",
    "            # Scores standards\n",
    "            curr_RMSE_standard.append(fct_RMSE(curr_test_Y_standard, predictions_Y_standard, [code])[\"RMSE\"][0])\n",
    "            curr_MAE_standard.append(fct_MAE(curr_test_Y_standard, predictions_Y_standard, [code])[\"MAE\"][0])\n",
    "            curr_R2_standard.append(fct_R2(curr_test_Y_standard, predictions_Y_standard, [code])[\"R2\"][0])\n",
    "            # Score\n",
    "            predictions_Y = fct_StandardizeInverse(predictions_Y_standard, \n",
    "                                                   curr_train_X_mean, curr_train_X_std, \n",
    "                                                   [code])\n",
    "            predictions_Y[\"Date\"] = predictions_Y_standard[\"Date\"].values\n",
    "            curr_RMSE.append(fct_RMSE(curr_test_Y, predictions_Y, [code])[\"RMSE\"][0])\n",
    "            curr_MAE.append(fct_MAE(curr_test_Y, predictions_Y, [code])[\"MAE\"][0])\n",
    "            curr_R2.append(fct_R2(curr_test_Y, predictions_Y, [code])[\"R2\"][0])\n",
    "\n",
    "        # On rassemble\n",
    "        cv_scores_RMSE_standard[\"Split_\" + str(curr_split)] = curr_RMSE_standard\n",
    "        cv_scores_MAE_standard[\"Split_\" + str(curr_split)] = curr_MAE_standard\n",
    "        cv_scores_R2_standard[\"Split_\" + str(curr_split)] = curr_R2_standard\n",
    "\n",
    "        cv_scores_RMSE[\"Split_\" + str(curr_split)] = curr_RMSE\n",
    "        cv_scores_MAE[\"Split_\" + str(curr_split)] = curr_MAE\n",
    "        cv_scores_R2[\"Split_\" + str(curr_split)] = curr_R2\n",
    "\n",
    "    # Calcul des scores moyens du split\n",
    "    cv_moyen_RMSE_standard = []\n",
    "    cv_moyen_MAE_standard = []\n",
    "    cv_moyen_R2_standard = []\n",
    "    cv_moyen_RMSE = []\n",
    "    cv_moyen_MAE = []\n",
    "    cv_moyen_R2 = []\n",
    "\n",
    "    for code in liste_stations_debit:\n",
    "        score_RMSE = np.mean(cv_scores_RMSE_standard[cv_scores_RMSE_standard[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "        cv_moyen_RMSE_standard.append(score_RMSE)\n",
    "        score_MAE = np.mean(cv_scores_MAE_standard[cv_scores_MAE_standard[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "        cv_moyen_MAE_standard.append(score_MAE)\n",
    "        score_R2 = np.mean(cv_scores_R2_standard[cv_scores_R2_standard[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "        cv_moyen_R2_standard.append(score_R2)\n",
    "        score_RMSE = np.mean(cv_scores_RMSE[cv_scores_RMSE[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "        cv_moyen_RMSE.append(score_RMSE)\n",
    "        score_MAE = np.mean(cv_scores_MAE[cv_scores_MAE[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "        cv_moyen_MAE.append(score_MAE)\n",
    "        score_R2 = np.mean(cv_scores_R2[cv_scores_R2[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "        cv_moyen_R2.append(score_R2)\n",
    "\n",
    "    cv_scores_RMSE_standard[\"Moyenne\"] = cv_moyen_RMSE_standard\n",
    "    cv_scores_RMSE_standard.to_csv(\"../Data/GAMaggregAR/CV_RMSE_standard_\"+ \"_\" + str(curr_lag) + \".csv\",    \n",
    "                          index=False)\n",
    "    cv_scores_MAE_standard[\"Moyenne\"] = cv_moyen_MAE_standard\n",
    "    cv_scores_MAE_standard.to_csv(\"../Data/GAMaggregAR/CV_MAE_standard_\"  + \"_\" + str(curr_lag) + \".csv\",\n",
    "                          index=False)\n",
    "    cv_scores_R2_standard[\"Moyenne\"] = cv_moyen_R2_standard\n",
    "    cv_scores_R2_standard.to_csv(\"../Data/GAMaggregAR/CV_R2_standard_\"  + \"_\" + str(curr_lag) + \".csv\",\n",
    "                          index=False)\n",
    "    cv_scores_RMSE[\"Moyenne\"] = cv_moyen_RMSE\n",
    "    cv_scores_RMSE.to_csv(\"../Data/GAMaggregAR/CV_RMSE_\"  + \"_\" + str(curr_lag) + \".csv\",\n",
    "                          index=False)\n",
    "    cv_scores_MAE[\"Moyenne\"] = cv_moyen_MAE\n",
    "    cv_scores_MAE.to_csv(\"../Data/GAMaggregAR/CV_MAE_\"  + \"_\" + str(curr_lag) + \".csv\",\n",
    "                          index=False)\n",
    "    cv_scores_R2[\"Moyenne\"] = cv_moyen_R2\n",
    "    cv_scores_R2.to_csv(\"../Data/GAMaggregAR/CV_R2_\"  + \"_\" + str(curr_lag) + \".csv\",\n",
    "                          index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d589c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_train_X_standard_residus[code].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366761a-87df-4e2e-8b01-12a21cbe4ae4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "colonnes_meteo_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7ad0e-3717-4b5f-b654-be16ba4dbd9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819eda28-32e9-45df-96eb-3f544562eac8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cours_eau = 3\n",
    "cours_eau = list(np.unique(stations_debit[\"Cours eau\"]))\n",
    "cours_eau_cmap = cm.get_cmap(ListedColormap([\"red\", \"green\", \"blue\"]))\n",
    "cours_eau_couleur = pd.DataFrame({\"Cours eau\": cours_eau, \"Index\": range(n_cours_eau), \"Couleur\": [\"red\", \"green\", \"blue\"]})\n",
    "cours_eau_couleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f8fff-6421-4623-8bf1-33c74b8ca232",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lr in lr_grid:\n",
    "    curr_moyen = {}\n",
    "    cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_RMSE_lr_\" + str(curr_lr) + \".csv\")\n",
    "    for code in liste_stations_debit:\n",
    "        curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "    curr_moyen = pd.DataFrame(curr_moyen)\n",
    "    curr_moyen[\"lr\"] = curr_lr/1000\n",
    "    cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, 1, figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        axs[i].plot(cv_moyen[\"lr\"], cv_moyen[code],\n",
    "                   color = cours_eau_cmap(i))\n",
    "        axs[i].set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb63cdd-51fd-4507-bacf-9010be71a177",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lr in lr_grid:\n",
    "    curr_moyen = {}\n",
    "    cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_MAE_lr_\" + str(curr_lr) + \".csv\")\n",
    "    for code in liste_stations_debit:\n",
    "        curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "    curr_moyen = pd.DataFrame(curr_moyen)\n",
    "    curr_moyen[\"lr\"] = curr_lr/1000\n",
    "    cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, 1, figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        axs[i].plot(cv_moyen[\"lr\"], cv_moyen[code],\n",
    "                   color = cours_eau_cmap(i))\n",
    "        axs[i].set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97342c8f-b28b-48ae-9f57-34d27b922168",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lr in lr_grid:\n",
    "    curr_moyen = {}\n",
    "    cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_R2_lr_\" + str(curr_lr) + \".csv\")\n",
    "    for code in liste_stations_debit:\n",
    "        curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "    curr_moyen = pd.DataFrame(curr_moyen)\n",
    "    curr_moyen[\"lr\"] = curr_lr/1000\n",
    "    cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, 1, figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        axs[i].plot(cv_moyen[\"lr\"], cv_moyen[code],\n",
    "                   color = cours_eau_cmap(i))\n",
    "        axs[i].set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f6b7b-6157-44ca-9696-fe3824c28e8b",
   "metadata": {},
   "source": [
    "## Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00efb65-f12b-4490-b3c5-cb53804ce78e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lr in lr_grid:\n",
    "    curr_moyen = {}\n",
    "    cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_RMSE_standard_lr_\" + str(curr_lr) + \".csv\")\n",
    "    for code in liste_stations_debit:\n",
    "        curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "    curr_moyen = pd.DataFrame(curr_moyen)\n",
    "    curr_moyen[\"lr\"] = curr_lr/1000\n",
    " + \".csv\")    cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, 1, figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        axs[i].plot(cv_moyen[\"lr\"], cv_moyen[code],\n",
    "                   color = cours_eau_cmap(i))\n",
    "        axs[i].set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3f190-39d9-42a0-b1fb-eb56073dac81",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lr in lr_grid:\n",
    "    curr_moyen = {}\n",
    "    cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_MAE_standard_lr_\" + str(curr_lr) + \".csv\")\n",
    "    for code in liste_stations_debit:\n",
    "        curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "    curr_moyen = pd.DataFrame(curr_moyen)\n",
    "    curr_moyen[\"lr\"] = curr_lr/1000\n",
    "    cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, 1, figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        axs[i].plot(cv_moyen[\"lr\"], cv_moyen[code],\n",
    "                   color = cours_eau_cmap(i))\n",
    "        axs[i].set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809a4cb-c188-490e-8dbb-d9962dfb95fb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lr in lr_grid:\n",
    "    curr_moyen = {}\n",
    "    cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_R2_standard_lr_\" + str(curr_lr) + \".csv\")\n",
    "    for code in liste_stations_debit:\n",
    "        curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "    curr_moyen = pd.DataFrame(curr_moyen)\n",
    "    curr_moyen[\"lr\"] = curr_lr/1000\n",
    "    cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, 1, figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        axs[i].plot(cv_moyen[\"lr\"], cv_moyen[code],\n",
    "                   color = cours_eau_cmap(i))\n",
    "        axs[i].set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1ecee-9eb8-4953-ad7a-efbc07a9fd34",
   "metadata": {},
   "source": [
    "## Moyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c518f-5a58-4ab0-bd86-ca4316c70175",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lag in range(max_lag+1):\n",
    "    for curr_lr in lr_grid:\n",
    "        curr_moyen = {} \n",
    "        cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_RMSE_standard_\" + str(curr_lr) + \"_\" + str(curr_lag) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"lr\"] = curr_lr/1000\n",
    "        curr_moyen[\"Lags\"] = curr_lag\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715d107-be51-467a-8278-4312869b456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_moyen.groupby(\"lr\").mean().index, cv_moyen.groupby(\"lr\").mean()[liste_stations_debit].mean(axis = 1).values)\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig(\"../Data/Figures/GAMaggregAR/GAMaggregAR_RMSE_lr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c4cd7-7da7-4017-bd54-14680a31c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_moyen.groupby(\"Lags\").mean().index, cv_moyen.groupby(\"Lags\").mean()[liste_stations_debit].mean(axis = 1).values)\n",
    "plt.savefig(\"../Data/Figures/GAMaggregAR/GAMaggregAR_RMSE_AR.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d4432-845d-4d2f-b5db-8b5e1ec93b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lag in range(max_lag+1):\n",
    "    for curr_lr in lr_grid:\n",
    "        curr_moyen = {} \n",
    "        cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_MAE_standard_\" + str(curr_lr) + \"_\" + str(curr_lag) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"lr\"] = curr_lr/1000\n",
    "        curr_moyen[\"Lags\"] = curr_lag\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e9a4d-90a9-4f3b-b462-e1ec594de7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_moyen.groupby(\"lr\").mean().index, cv_moyen.groupby(\"lr\").mean()[liste_stations_debit].mean(axis = 1).values)\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig(\"../Data/Figures/GAMaggregAR/GAMaggregAR_MAE_lr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988a053-0af1-4d04-9778-8a259f43b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_moyen.groupby(\"Lags\").mean().index, cv_moyen.groupby(\"Lags\").mean()[liste_stations_debit].mean(axis = 1).values)\n",
    "plt.savefig(\"../Data/Figures/GAMaggregAR/GAMaggregAR_MAE_AR.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f138cab-6305-4224-85cf-3900c2e1a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_lag in range(max_lag+1):\n",
    "    for curr_lr in lr_grid:\n",
    "        curr_moyen = {} \n",
    "        cv_scores = pd.read_csv(\"../Data/GAMaggregAR/CV_R2_standard_\" + str(curr_lr) + \"_\" + str(curr_lag) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"lr\"] = curr_lr/1000\n",
    "        curr_moyen[\"Lags\"] = curr_lag\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88716ef-f4e0-4d7c-882f-419fe76067fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_moyen.groupby(\"lr\").mean().index, cv_moyen.groupby(\"lr\").mean()[liste_stations_debit].mean(axis = 1).values)\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig(\"../Data/Figures/GAMaggregAR/GAMaggregAR_R2_lr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221a677-c8b9-43e3-b507-354e4cd63d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cv_moyen.groupby(\"Lags\").mean().index, cv_moyen.groupby(\"Lags\").mean()[liste_stations_debit].mean(axis = 1).values)\n",
    "plt.savefig(\"../Data/Figures/GAMaggregAR/GAMaggregAR_R2_AR.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb63b23-803c-4db2-b015-0e4ceac78a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../Data/GAMaggregAR/CV_RMSE_standard_30_0.csv\")[\"Moyenne\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540949d9-0aee-434c-939a-c4af87b87546",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../Data/GAMaggregAR/CV_MAE_standard_30_0.csv\")[\"Moyenne\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6351422-08c1-4124-ae54-245087e26077",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../Data/GAMaggregAR/CV_R2_standard_30_0.csv\")[\"Moyenne\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b546cd-b011-40e7-bfda-b739c6531a21",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d4df88e-e968-418d-bdae-3bfc80075d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e6925f2-3461-45c6-9fce-75678cc218d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donnees\n",
    "mesures_train_X_mean = mesures_train_X[liste_stations_debit + colonnes_meteo_stations].mean()\n",
    "mesures_train_X_std = mesures_train_X[liste_stations_debit + colonnes_meteo_stations].std()\n",
    "mesures_train_X_standard = fct_Standardize(mesures_train_X, \n",
    "                                           mesures_train_X_mean, mesures_train_X_std, \n",
    "                                           liste_stations_debit + colonnes_meteo_stations)\n",
    "mesures_train_X_standard[\"Date\"] = mesures_train_X[\"Date\"]\n",
    "\n",
    "mesures_test_X_standard =fct_Standardize(mesures_test_X, mesures_train_X_mean, mesures_train_X_std, \n",
    "                                         liste_stations_debit + colonnes_meteo_stations)\n",
    "mesures_test_X_standard[\"Date\"] = mesures_test_X[\"Date\"].values\n",
    "mesures_test_Y_standard = fct_Standardize(mesures_test_Y, mesures_train_X_mean, mesures_train_X_std, \n",
    "                                          liste_stations_debit)\n",
    "mesures_test_Y_standard[\"Date\"] = mesures_test_Y[\"Date\"]\n",
    "liste_dates = mesures_test_Y[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6a3aa27-10de-4d3e-8de6-9a5985d20530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]/home/wendong/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- H0100010_0\n",
      "- H0100010_1\n",
      "- H0100010_2\n",
      "- H0100010_3\n",
      "- H0100010_4\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 245 features, but Lasso is expecting 461 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2964/883075381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Predictions Standard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mpredictions_Y_standard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesures_test_X_standard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolonnes_meteo_stations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mpredictions_Y_standard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_Y_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mpredictions_Y_standard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmesures_test_X_standard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights_not_none\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 245 features, but Lasso is expecting 461 features as input."
     ]
    }
   ],
   "source": [
    "scores_RMSE_standard = []\n",
    "scores_MAE_standard = []\n",
    "scores_R2_standard = []\n",
    "scores_RMSE = []\n",
    "scores_MAE = []\n",
    "scores_R2 = []\n",
    "\n",
    "predictions_test_Y_standard = mesures_test_Y[[\"Date\"]]\n",
    "predictions_test_Y = mesures_test_Y[[\"Date\"]]\n",
    "\n",
    "for code in tqdm(liste_stations_debit):\n",
    "        # Entrainement\n",
    "        # Entrainement\n",
    "        reg1 = linear_model.Lasso(alpha = curr_alpha/1000, max_iter = 30000)\n",
    "        #reg2 = PLSRegression(n_components=curr_compo)\n",
    "        reg2 = RandomForestRegressor(max_features=curr_feature,\n",
    "                                        max_samples=curr_sample/10)\n",
    "        #reg3 = GradientBoostingRegressor(learning_rate = lr)\n",
    "\n",
    "        reg1.fit(X = curr_train_X_standard_residus[colonnes_reg],\n",
    "          y = curr_train_X_standard_residus[code])\n",
    "        #reg2.fit(X = curr_train_X_standard_residus[colonnes_reg], Y = curr_train_X_standard_residus[code])\n",
    "        reg2.fit(X = curr_train_X_standard_residus[colonnes_reg],\n",
    "          y = curr_train_X_standard_residus[code])\n",
    "        #reg3.fit(X = curr_train_X_standard_residus[colonnes_reg],\n",
    "          #y = curr_train_X_standard_residus[code])\n",
    "\n",
    "        #model = VotingRegressor([(\"LASSO\", reg1), (\"PLS\", reg2), (\"RF\", reg3)])\n",
    "        model = VotingRegressor([(\"LASSO\", reg1), (\"Random Forest\", reg2)])\n",
    "        model.fit(X= curr_train_X_standard_residus[colonnes_reg], y = curr_train_X_standard_residus[code])\n",
    "\n",
    "        # Predictions Standard\n",
    "        predictions_Y_standard = model.predict(mesures_test_X_standard[colonnes_meteo_stations])\n",
    "        predictions_Y_standard = pd.DataFrame(predictions_Y_standard, columns=[code])\n",
    "        predictions_Y_standard[\"Date\"] = mesures_test_X_standard[\"Date\"].values\n",
    "        # Filtre sur les dates\n",
    "        resultat = pd.DataFrame()\n",
    "        for curr_date in liste_dates:\n",
    "            resultat = pd.concat([resultat, predictions_Y_standard[predictions_Y_standard[\"Date\"] == curr_date]])\n",
    "        resultat = resultat.sort_values(by = \"Date\")\n",
    "        predictions_Y_standard = resultat.copy()\n",
    "        predictions_test_Y_standard = predictions_test_Y_standard.merge(predictions_Y_standard)\n",
    "        \n",
    "        predictions_Y = fct_StandardizeInverse(predictions_Y_standard, \n",
    "                                                   mesures_train_X_mean, mesures_train_X_std, \n",
    "                                                   [code])\n",
    "        predictions_Y[\"Date\"] = predictions_Y_standard[\"Date\"].values\n",
    "        predictions_test_Y = predictions_test_Y.merge(predictions_Y)\n",
    "        \n",
    "        # Scores standards\n",
    "        scores_RMSE_standard.append(fct_RMSE(mesures_test_Y_standard, predictions_Y_standard, [code])[\"RMSE\"][0])\n",
    "        scores_MAE_standard.append(fct_MAE(mesures_test_Y_standard, predictions_Y_standard, [code])[\"MAE\"][0])\n",
    "        scores_R2_standard.append(fct_R2(mesures_test_Y_standard, predictions_Y_standard, [code])[\"R2\"][0])\n",
    "        # Score\n",
    "        scores_RMSE.append(fct_RMSE(mesures_test_Y, predictions_Y, [code])[\"RMSE\"][0])\n",
    "        scores_MAE.append(fct_MAE(mesures_test_Y, predictions_Y, [code])[\"MAE\"][0])\n",
    "        scores_R2.append(fct_R2(mesures_test_Y, predictions_Y, [code])[\"R2\"][0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382f33f-4913-4ea7-bbd0-b4020f4f61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = pd.DataFrame({\"Code station\": liste_stations_debit,\n",
    "                            \"RMSE\": scores_RMSE,\n",
    "                            \"MAE\": scores_MAE,\n",
    "                            \"R2\": scores_R2})\n",
    "test_scores.to_csv(\"../Data/GAMaggregAR/Test_scores.csv\")\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e650086-8f4d-459b-9b3b-e17e68ed6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_standard = pd.DataFrame({\"Code station\": liste_stations_debit,\n",
    "                            \"RMSE\": scores_RMSE,\n",
    "                            \"MAE\": scores_MAE,\n",
    "                            \"R2\": scores_R2})\n",
    "test_scores_standard.to_csv(\"../Data/GAMaggregAR/Test_scores_standard.csv\")\n",
    "test_scores_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a19d21b-9d11-49d1-9b90-a14fc12e0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_standard[[\"RMSE\", \"MAE\", \"R2\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415553c-cdaf-4e30-84a3-e94c1b0ae4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stations = len(liste_stations_debit)\n",
    "fig, axs = plt.subplots(n_stations, 1, figsize = (15,30), sharex=True)\n",
    "for i in range(n_stations):\n",
    "    code = liste_stations_debit[i]\n",
    "    axs[i].plot(mesures_test_Y_standard[code], label = \"True\")\n",
    "    axs[i].plot(predictions_test_Y_standard[code], label = \"Predictions\")\n",
    "    axs[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780d10b-c50d-4704-8573-8f505095a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stations = len(liste_stations_debit)\n",
    "fig, axs = plt.subplots(n_stations, 1, figsize = (15,30), sharex=True)\n",
    "for i in range(n_stations):\n",
    "    code = liste_stations_debit[i]\n",
    "    axs[i].plot(mesures_test_Y[code], label = \"True\")\n",
    "    axs[i].plot(predictions_test_Y[code], label = \"Predictions\")\n",
    "    axs[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab74395-3ce5-42bd-bdae-87f1d887c33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
