{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5b0b29-f218-42be-ad49-250258fa3f5c",
   "metadata": {},
   "source": [
    "On rajoute les données meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ade40bd-d76a-496b-a920-9cf77202eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46710d7f-b791-41d9-8e44-3e5b41f8d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_debit = pd.read_csv(\"../Data/Base/Stations_Debit.csv\")\n",
    "liste_stations_debit = list(stations_debit[\"Code station\"])\n",
    "\n",
    "mesures_train_X = pd.read_csv(\"../Data/Base/Mesures_Train_X.csv\")\n",
    "mesures_train_X[\"Date\"] = pd.to_datetime(mesures_train_X[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")\n",
    "mesures_train_Y = pd.read_csv(\"../Data/Base/Mesures_Train_Y.csv\")\n",
    "mesures_train_Y[\"Date\"] = pd.to_datetime(mesures_train_Y[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "train_split_X = pd.read_csv(\"../Data/Base/Index_CV_X.csv\")\n",
    "train_split_Y = pd.read_csv(\"../Data/Base/Index_CV_Y.csv\")\n",
    "\n",
    "mesures_test_X = pd.read_csv(\"../Data/Base/Mesures_Test_X.csv\")\n",
    "mesures_test_X[\"Date\"] = pd.to_datetime(mesures_test_X[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")\n",
    "mesures_test_Y = pd.read_csv(\"../Data/Base/Mesures_Test_Y.csv\")\n",
    "mesures_test_Y[\"Date\"] = pd.to_datetime(mesures_test_Y[\"Date\"], format = \"%Y/%m/%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8752eee-0b85-4a1f-9781-d7b6d3d9e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_meteo = pd.read_csv(\"../Data/Base/Stations_Meteo.csv\")\n",
    "liste_stations_meteo = list(stations_meteo[\"ID\"].apply(lambda x: str(x).rjust(5, \"0\")))\n",
    "colonnes_meteo = [\"Pression\", \"Vent_Nord\", \"Vent_Est\", \"Vitesse_vent\", \"Temperature\", \"Humidite\", \"Precipitations\"]\n",
    "tempo = []\n",
    "for code in liste_stations_meteo:\n",
    "    tempo += [tp + \"_\" + code for tp in colonnes_meteo]\n",
    "colonnes_meteo_stations = tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9732a271-7af8-4f7c-8840-2dcbbb4bb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Eval_fcts.py\n",
    "%run Standardize_fcts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7397ec6c-ae5f-4733-9b46-80c8b189caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Regression_GAM_Gamma.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b81e78-551c-47ca-9e0b-ebd3d94d52ea",
   "metadata": {},
   "source": [
    "# Val croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc824b6-c613-4357-8487-2771b576a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 3\n",
    "feature_grid = [\"auto\"]\n",
    "sample_grid = [2, 4, 6, 8, 10]\n",
    "n_knots = 10\n",
    "\n",
    "sample_grid = [10]\n",
    "min_lag = 0\n",
    "max_lag = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd14f45-0ebd-45df-83df-cd71c897e2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 8/8 [1:36:07<00:00, 720.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        for curr_lag in tqdm(range(min_lag, max_lag+1)):\n",
    "        \n",
    "            cv_scores_RMSE_standard = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "            cv_scores_MAE_standard = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "            cv_scores_R2_standard = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "\n",
    "            cv_scores_RMSE = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "            cv_scores_MAE = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "            cv_scores_R2 = pd.DataFrame({\"Code station\": liste_stations_debit})\n",
    "    \n",
    "            for curr_split in range(9):\n",
    "        \n",
    "            # Entraintement\n",
    "                curr_train_X = mesures_train_X[train_split_X[\"Train_\" + str(curr_split)]]\n",
    "                curr_train_Y = mesures_train_Y[train_split_Y[\"Train_\" + str(curr_split)]]\n",
    "                curr_train_X_mean = curr_train_X[liste_stations_debit + colonnes_meteo_stations].mean()\n",
    "                for code in liste_stations_debit:\n",
    "                    curr_train_X_mean[code] = 0\n",
    "                curr_train_X_std = curr_train_X[liste_stations_debit + colonnes_meteo_stations].std()\n",
    "                curr_train_X_standard = fct_Standardize(curr_train_X, curr_train_X_mean,\n",
    "                                                    curr_train_X_std, liste_stations_debit + colonnes_meteo_stations)\n",
    "                curr_train_X_standard[\"Date\"] = curr_train_X[\"Date\"]\n",
    "                    #GAM\n",
    "                spline_fit = fct_Regression_SplineGamma_fit(curr_train_X_standard, liste_stations_debit, n_knots)\n",
    "                curr_train_X_standard_residus = fct_Regression_SplineGamma_residus(spline_fit, \n",
    "                                                                                   curr_train_X_standard, \n",
    "                                                                                   liste_stations_debit)\n",
    "                curr_train_X_standard_residus = pd.concat([curr_train_X_standard_residus, \n",
    "                                                          curr_train_X_standard[colonnes_meteo_stations]],\n",
    "                                                         axis = 1)\n",
    "                    # Ajout AR\n",
    "                colonnes_reg = colonnes_meteo_stations\n",
    "                for i in range(curr_lag+1):\n",
    "                    variable = curr_train_X_standard_residus[liste_stations_debit].shift(i+7)\n",
    "                    variable.columns = [code+\"_\"+str(i) for code in liste_stations_debit]\n",
    "                    curr_train_X_standard_residus = pd.concat([curr_train_X_standard_residus, variable], axis = 1)\n",
    "                    colonnes_reg = colonnes_reg + [code+\"_\"+str(i) for code in liste_stations_debit]\n",
    "                curr_train_X_standard_residus = curr_train_X_standard_residus[(7+curr_lag):]\n",
    "                \n",
    "                    # RF\n",
    "                model_RF = RandomForestRegressor(max_features=curr_feature,\n",
    "                                                max_samples=curr_sample/10)\n",
    "                model_RF.fit(X = curr_train_X_standard_residus[colonnes_reg],\n",
    "                             y = curr_train_X_standard_residus[liste_stations_debit])\n",
    "        \n",
    "                # Predictions Standard\n",
    "                curr_test_X = mesures_train_X[train_split_X[\"Test_\" + str(curr_split)]]\n",
    "                curr_test_Y = mesures_train_Y[train_split_Y[\"Test_\" + str(curr_split)]]\n",
    "                liste_dates = curr_test_Y[\"Date\"]\n",
    "                curr_test_X_standard =fct_Standardize(curr_test_X, curr_train_X_mean,\n",
    "                                                  curr_train_X_std, liste_stations_debit + colonnes_meteo_stations)\n",
    "                curr_test_X_standard[\"Date\"] = curr_test_X[\"Date\"].values\n",
    "                curr_test_X_standard_residus = fct_Regression_SplineGamma_residus(spline_fit,\n",
    "                                                                              curr_test_X_standard, \n",
    "                                                                              liste_stations_debit)\n",
    "                curr_test_X_standard_residus = pd.concat([curr_test_X_standard_residus, \n",
    "                                                          curr_test_X_standard[colonnes_meteo_stations]],\n",
    "                                                         axis = 1)\n",
    "                    # Ajout variables AR\n",
    "                for i in range(curr_lag+1):\n",
    "                    variable = curr_test_X_standard_residus[liste_stations_debit].shift(i+7)\n",
    "                    variable.columns = [code+\"_\"+str(i) for code in liste_stations_debit]\n",
    "                    curr_test_X_standard_residus = pd.concat([curr_test_X_standard_residus, variable], axis = 1)\n",
    "                curr_test_X_standard_residus = curr_test_X_standard_residus[(7+curr_lag):]\n",
    "                    # RF\n",
    "                predictions_test_Y_standard_residus = model_RF.predict(curr_test_X_standard_residus[colonnes_reg])\n",
    "                predictions_test_Y_standard_residus = pd.DataFrame(predictions_test_Y_standard_residus, columns=liste_stations_debit)\n",
    "                predictions_test_Y_standard_residus[\"Date\"] = curr_test_X_standard_residus[\"Date\"].values\n",
    "                # Filtre sur les dates\n",
    "                resultat = pd.DataFrame()\n",
    "                for curr_date in liste_dates:\n",
    "                    resultat = pd.concat([resultat, predictions_test_Y_standard_residus[predictions_test_Y_standard_residus[\"Date\"] == curr_date]])\n",
    "                resultat = resultat.sort_values(by = \"Date\")\n",
    "                predictions_test_Y_standard_residus = resultat.copy()\n",
    "                # On rajoute la compo saisonnalité\n",
    "                predictions_test_Y_standard_saisonnalite = fct_Regression_SplineGamma_predict(spline_fit, liste_dates, liste_stations_debit)\n",
    "                predictions_test_Y_standard = predictions_test_Y_standard_residus[[\"Date\"]].copy()\n",
    "                for code in liste_stations_debit:\n",
    "                    predictions_test_Y_standard[code] = predictions_test_Y_standard_residus[code].values + predictions_test_Y_standard_saisonnalite[code].values\n",
    "\n",
    "        \n",
    "                # Score standard\n",
    "                curr_test_Y_standard = fct_Standardize(curr_test_Y, \n",
    "                                                       curr_train_X_mean, curr_train_X_std, \n",
    "                                                       liste_stations_debit)\n",
    "                curr_test_Y_standard[\"Date\"] = curr_test_Y[\"Date\"]\n",
    "                curr_RMSE = fct_RMSE(curr_test_Y_standard, predictions_test_Y_standard, liste_stations_debit)\n",
    "                cv_scores_RMSE_standard[\"Split_\" + str(curr_split)] = curr_RMSE[\"RMSE\"]\n",
    "                curr_MAE = fct_MAE(curr_test_Y_standard, predictions_test_Y_standard, liste_stations_debit)\n",
    "                cv_scores_MAE_standard[\"Split_\" + str(curr_split)] = curr_MAE[\"MAE\"]\n",
    "                curr_R2 = fct_R2(curr_test_Y_standard, predictions_test_Y_standard, liste_stations_debit)\n",
    "                cv_scores_R2_standard[\"Split_\" + str(curr_split)] = curr_R2[\"R2\"]\n",
    "                # Score\n",
    "                predictions_test_Y = fct_StandardizeInverse(predictions_test_Y_standard, \n",
    "                                                       curr_train_X_mean, curr_train_X_std, \n",
    "                                                       liste_stations_debit)\n",
    "                predictions_test_Y[\"Date\"] = predictions_test_Y_standard[\"Date\"].values\n",
    "                curr_RMSE = fct_RMSE(curr_test_Y, predictions_test_Y, liste_stations_debit)\n",
    "                cv_scores_RMSE[\"Split_\" + str(curr_split)] = curr_RMSE[\"RMSE\"]\n",
    "                curr_MAE = fct_MAE(curr_test_Y, predictions_test_Y, liste_stations_debit)\n",
    "                cv_scores_MAE[\"Split_\" + str(curr_split)] = curr_MAE[\"MAE\"]\n",
    "                curr_R2 = fct_R2(curr_test_Y, predictions_test_Y, liste_stations_debit)\n",
    "                cv_scores_R2[\"Split_\" + str(curr_split)] = curr_R2[\"R2\"]\n",
    "    \n",
    "            cv_moyen_RMSE_standard = []\n",
    "            cv_moyen_MAE_standard = []\n",
    "            cv_moyen_R2_standard = []\n",
    "\n",
    "            cv_moyen_RMSE = []\n",
    "            cv_moyen_MAE = []\n",
    "            cv_moyen_R2 = []\n",
    "\n",
    "            for code in liste_stations_debit:\n",
    "                score_RMSE = np.mean(cv_scores_RMSE_standard[cv_scores_RMSE_standard[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "                cv_moyen_RMSE_standard.append(score_RMSE)\n",
    "                score_MAE = np.mean(cv_scores_MAE_standard[cv_scores_MAE_standard[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "                cv_moyen_MAE_standard.append(score_MAE)\n",
    "                score_R2 = np.mean(cv_scores_R2_standard[cv_scores_R2_standard[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "                cv_moyen_R2_standard.append(score_R2)\n",
    "                score_RMSE = np.mean(cv_scores_RMSE[cv_scores_RMSE[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "                cv_moyen_RMSE.append(score_RMSE)\n",
    "                score_MAE = np.mean(cv_scores_MAE[cv_scores_MAE[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "                cv_moyen_MAE.append(score_MAE)\n",
    "                score_R2 = np.mean(cv_scores_R2[cv_scores_R2[\"Code station\"] == code][[\"Split_\" + str(i) for i in range(9)]].iloc[0,:])\n",
    "                cv_moyen_R2.append(score_R2)\n",
    "\n",
    "            cv_scores_RMSE_standard[\"Moyenne\"] = cv_moyen_RMSE_standard\n",
    "            cv_scores_RMSE_standard.to_csv(\"../Data/GAMRandomForestAR/CV_RMSE_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \"_\" + str(curr_lag) + \".csv\",\n",
    "                                  index=False)\n",
    "            cv_scores_MAE_standard[\"Moyenne\"] = cv_moyen_MAE_standard\n",
    "            cv_scores_MAE_standard.to_csv(\"../Data/GAMRandomForestAR/CV_MAE_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \"_\" + str(curr_lag) + \".csv\",\n",
    "                                  index=False)\n",
    "            cv_scores_R2_standard[\"Moyenne\"] = cv_moyen_R2_standard\n",
    "            cv_scores_R2_standard.to_csv(\"../Data/GAMRandomForestAR/CV_R2_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \"_\" + str(curr_lag) + \".csv\",\n",
    "                                  index=False)\n",
    "            cv_scores_RMSE[\"Moyenne\"] = cv_moyen_RMSE\n",
    "            cv_scores_RMSE.to_csv(\"../Data/GAMRandomForestAR/CV_RMSE_\" + str(curr_feature) + \"_\" + str(curr_sample) + \"_\" + str(curr_lag) + \".csv\",\n",
    "                                  index=False)\n",
    "            cv_scores_MAE[\"Moyenne\"] = cv_moyen_MAE\n",
    "            cv_scores_MAE.to_csv(\"../Data/GAMRandomForestAR/CV_MAE_\" + str(curr_feature) + \"_\" + str(curr_sample) + \"_\" + str(curr_lag) + \".csv\",\n",
    "                                  index=False)\n",
    "            cv_scores_R2[\"Moyenne\"] = cv_moyen_R2\n",
    "            cv_scores_R2.to_csv(\"../Data/GAMRandomForestAR/CV_R2_\" + str(curr_feature) + \"_\" + str(curr_sample) + \"_\" + str(curr_lag) + \".csv\",\n",
    "                                  index=False)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7ad0e-3717-4b5f-b654-be16ba4dbd9c",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819eda28-32e9-45df-96eb-3f544562eac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cours eau</th>\n",
       "      <th>Index</th>\n",
       "      <th>Couleur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Garonne</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loire</td>\n",
       "      <td>1</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seine</td>\n",
       "      <td>2</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cours eau  Index Couleur\n",
       "0   Garonne      0     red\n",
       "1     Loire      1   green\n",
       "2     Seine      2    blue"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cours_eau = 3\n",
    "cours_eau = list(np.unique(stations_debit[\"Cours eau\"]))\n",
    "cours_eau_cmap = cm.get_cmap(ListedColormap([\"red\", \"green\", \"blue\"]))\n",
    "cours_eau_couleur = pd.DataFrame({\"Cours eau\": cours_eau, \"Index\": range(n_cours_eau), \"Couleur\": [\"red\", \"green\", \"blue\"]})\n",
    "cours_eau_couleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d7f8fff-6421-4623-8bf1-33c74b8ca232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 77.45it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3097/2102343117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             axs[i,j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[0]][\"Max_samples\"], \n\u001b[0m\u001b[1;32m     20\u001b[0m                           \u001b[0mcv_moyen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcv_moyen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Max_features\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfeature_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                           color = cours_eau_cmap(i))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "curr_feature=\"auto\"\n",
    "for curr_lag in tqdm(range(min_lag, max_lag+1)):\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_RMSE_\" + str(curr_feature) + \"_\" + str(curr_sample) +\"_\"+ str(curr_lag)+ \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, len(feature_grid), figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        for j in range(len(feature_grid)):\n",
    "            axs[i,j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[0]][\"Max_samples\"], \n",
    "                          cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[0]][code],\n",
    "                          color = cours_eau_cmap(i))\n",
    "            axs[i,j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62079887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "0    True\n",
       "0    True\n",
       "0    True\n",
       "0    True\n",
       "0    True\n",
       "0    True\n",
       "0    True\n",
       "Name: Max_features, dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_moyen[\"Max_features\"] == feature_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90fd194f-0daa-4b80-a2c8-7e8414b26e32",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/GAMRandomForestAR/CV_MAE_auto_10.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3097/2031384698.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcurr_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_grid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcurr_moyen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/GAMRandomForestAR/CV_MAE_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_feature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mliste_stations_debit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcurr_moyen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Code station\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Moyenne\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/GAMRandomForestAR/CV_MAE_auto_10.csv'"
     ]
    }
   ],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_MAE_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, len(feature_grid), figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        for j in range(len(feature_grid)):\n",
    "            axs[i,j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                          cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][code],\n",
    "                          color = cours_eau_cmap(i))\n",
    "            axs[i,j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb63cdd-51fd-4507-bacf-9010be71a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_R2_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, len(feature_grid), figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        for j in range(len(feature_grid)):\n",
    "            axs[i,j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                          cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][code],\n",
    "                          color = cours_eau_cmap(i))\n",
    "            axs[i,j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97342c8f-b28b-48ae-9f57-34d27b922168",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_RMSE_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, len(feature_grid), figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        for j in range(len(feature_grid)):\n",
    "            axs[i,j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                          cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][code],\n",
    "                          color = cours_eau_cmap(i))\n",
    "            axs[i,j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50265a7-c9f8-4ff1-81be-04e0c9ff44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_MAE_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, len(feature_grid), figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        for j in range(len(feature_grid)):\n",
    "            axs[i,j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                          cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][code],\n",
    "                          color = cours_eau_cmap(i))\n",
    "            axs[i,j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615778b-230a-4c99-bdc8-7d4f41baf1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_R2_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(n_cours_eau, len(feature_grid), figsize = (15,5))\n",
    "for i in range(n_cours_eau):\n",
    "    stations = list(stations_debit[stations_debit[\"Cours eau\"] == list(cours_eau_couleur[cours_eau_couleur[\"Index\"] == i][\"Cours eau\"])[0]][\"Code station\"])\n",
    "    for code in stations:\n",
    "        for j in range(len(feature_grid)):\n",
    "            axs[i,j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                          cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][code],\n",
    "                          color = cours_eau_cmap(i))\n",
    "            axs[i,j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1ecee-9eb8-4953-ad7a-efbc07a9fd34",
   "metadata": {},
   "source": [
    "## Moyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c518f-5a58-4ab0-bd86-ca4316c70175",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_RMSE_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(feature_grid), figsize = (15,5), sharey=True)\n",
    "for j in range(len(feature_grid)):\n",
    "    axs[j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                  cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][liste_stations_debit].mean(axis = 1).values,)\n",
    "    axs[j].set_title(feature_grid[j])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53464340-9656-41f8-b48e-599671b6b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_MAE_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(feature_grid), figsize = (15,5), sharey=True)\n",
    "for j in range(len(feature_grid)):\n",
    "    axs[j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                  cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][liste_stations_debit].mean(axis = 1).values,)\n",
    "    axs[j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f36d4432-845d-4d2f-b5db-8b5e1ec93b9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/GAMRandomForestAR/CV_R2_standard_auto_10.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3097/1752403594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcurr_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_grid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcurr_moyen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/GAMRandomForestAR/CV_R2_standard_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_feature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mliste_stations_debit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcurr_moyen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Code station\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Moyenne\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/GAMRandomForestAR/CV_R2_standard_auto_10.csv'"
     ]
    }
   ],
   "source": [
    "cv_moyen = pd.DataFrame()\n",
    "\n",
    "for curr_feature in feature_grid:\n",
    "    for curr_sample in sample_grid:\n",
    "        curr_moyen = {}\n",
    "        cv_scores = pd.read_csv(\"../Data/GAMRandomForestAR/CV_R2_standard_\" + str(curr_feature) + \"_\" + str(curr_sample) + \".csv\")\n",
    "        for code in liste_stations_debit:\n",
    "            curr_moyen[code] = list(cv_scores[cv_scores[\"Code station\"] == code][\"Moyenne\"])\n",
    "        curr_moyen = pd.DataFrame(curr_moyen)\n",
    "        curr_moyen[\"Max_features\"] = curr_feature\n",
    "        curr_moyen[\"Max_samples\"] = curr_sample\n",
    "        cv_moyen = pd.concat([cv_moyen, curr_moyen])\n",
    "\n",
    "fig, axs = plt.subplots(1, len(feature_grid), figsize = (15,5), sharey=True)\n",
    "for j in range(len(feature_grid)):\n",
    "    axs[j].plot(cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][\"Max_samples\"], \n",
    "                  cv_moyen[cv_moyen[\"Max_features\"] == feature_grid[i]][liste_stations_debit].mean(axis = 1).values,)\n",
    "    axs[j].set_title(feature_grid[j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b546cd-b011-40e7-bfda-b739c6531a21",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4df88e-e968-418d-bdae-3bfc80075d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6925f2-3461-45c6-9fce-75678cc218d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donnees\n",
    "mesures_train_X_mean = mesures_train_X[liste_stations_debit + colonnes_meteo_stations].mean()\n",
    "mesures_train_X_std = mesures_train_X[liste_stations_debit + colonnes_meteo_stations].std()\n",
    "mesures_train_X_standard = fct_Standardize(mesures_train_X, \n",
    "                                           mesures_train_X_mean, mesures_train_X_std, \n",
    "                                           liste_stations_debit + colonnes_meteo_stations)\n",
    "mesures_train_X_standard[\"Date\"] = mesures_train_X[\"Date\"]\n",
    "\n",
    "mesures_test_X_standard =fct_Standardize(mesures_test_X, mesures_train_X_mean, mesures_train_X_std, \n",
    "                                         liste_stations_debit + colonnes_meteo_stations)\n",
    "mesures_test_X_standard[\"Date\"] = mesures_test_X[\"Date\"].values\n",
    "mesures_test_Y_standard = fct_Standardize(mesures_test_Y, mesures_train_X_mean, mesures_train_X_std, \n",
    "                                          liste_stations_debit)\n",
    "mesures_test_Y_standard[\"Date\"] = mesures_test_Y[\"Date\"]\n",
    "liste_dates = mesures_test_Y[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b29e88-49f0-4ff0-b69c-3b64f85199e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "model_RF = RandomForestRegressor(max_features=curr_feature,\n",
    "                                max_samples=sample)\n",
    "model_RF.fit(X = mesures_train_X_standard[colonnes_meteo_stations],\n",
    "      y = mesures_train_X_standard[liste_stations_debit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604a118-b67c-4302-99c8-f38e1a68f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions_test_Y_standard = model_RF.predict(mesures_test_X_standard[colonnes_meteo_stations])\n",
    "predictions_test_Y_standard = pd.DataFrame(predictions_test_Y_standard, columns=liste_stations_debit)\n",
    "predictions_test_Y_standard[\"Date\"] = mesures_test_X_standard[\"Date\"].values\n",
    "    # Filtre sur les dates\n",
    "resultat = pd.DataFrame()\n",
    "for curr_date in liste_dates:\n",
    "    resultat = pd.concat([resultat, predictions_test_Y_standard[predictions_test_Y_standard[\"Date\"] == curr_date]])\n",
    "resultat = resultat.sort_values(by = \"Date\")\n",
    "predictions_test_Y_standard = resultat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb685b8-30bf-4327-bb1d-508683b3981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_Y = fct_StandardizeInverse(predictions_test_Y_standard, mesures_train_X_mean,\n",
    "                                              mesures_train_X_std, liste_stations_debit)\n",
    "predictions_test_Y[\"Date\"] = predictions_test_Y_standard[\"Date\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45b5cc-9112-4f55-aea8-e3fb146a5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stations = len(liste_stations_debit)\n",
    "fig, axs = plt.subplots(n_stations, 1, figsize = (15,30), sharex=True)\n",
    "for i in range(n_stations):\n",
    "    code = liste_stations_debit[i]\n",
    "    axs[i].plot(mesures_test_Y_standard[\"Date\"], mesures_test_Y_standard[code], label = \"True\")\n",
    "    axs[i].plot(predictions_test_Y_standard[\"Date\"], predictions_test_Y_standard[code], label = \"Predictions\")\n",
    "    axs[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef7eec-7c3d-4407-a91e-5f1fdbd84fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rmse_standard = fct_RMSE(mesures_test_Y_standard, predictions_test_Y_standard, liste_stations_debit)\n",
    "scores_mae_standard = fct_MAE(mesures_test_Y_standard, predictions_test_Y_standard, liste_stations_debit)\n",
    "scores_r2_standard = fct_R2(mesures_test_Y_standard, predictions_test_Y_standard, liste_stations_debit)\n",
    "\n",
    "test_scores_standard = pd.DataFrame({\"Code station\": liste_stations_debit,\n",
    "                            \"RMSE\": scores_rmse_standard[\"RMSE\"],\n",
    "                            \"MAE\": scores_mae_standard[\"MAE\"],\n",
    "                            \"R2\": scores_r2_standard[\"R2\"]})\n",
    "test_scores_standard.to_csv(\"../Data/GAMRandomForestAR/Test_scores_standard.csv\",\n",
    "                   index = False)\n",
    "test_scores_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c568a0-72b5-40c2-a9bf-59a2cff8f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_standard[[\"RMSE\", \"MAE\", \"R2\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e75f97eb-282d-4570-b53d-d431992c291c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (352,) (351,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3097/1364345813.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfct_RMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesures_test_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_test_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliste_stations_debit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscores_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfct_MAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesures_test_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_test_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliste_stations_debit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfct_R2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesures_test_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_test_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliste_stations_debit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m test_scores = pd.DataFrame({\"Code station\": liste_stations_debit,\n",
      "\u001b[0;32m~/Documents/GitHub/StatML_ProjectML/Eval_fcts.py\u001b[0m in \u001b[0;36mfct_RMSE\u001b[0;34m(Y_true, Y_pred, liste_stations)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mliste_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mliste_stations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mliste_rmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresultat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Code station\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mliste_stations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RMSE\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mliste_rmse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresultat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (352,) (351,) "
     ]
    }
   ],
   "source": [
    "scores_rmse = fct_RMSE(mesures_test_Y, predictions_test_Y, liste_stations_debit)\n",
    "scores_mae = fct_MAE(mesures_test_Y, predictions_test_Y, liste_stations_debit)\n",
    "scores_r2 = fct_R2(mesures_test_Y, predictions_test_Y, liste_stations_debit)\n",
    "\n",
    "test_scores = pd.DataFrame({\"Code station\": liste_stations_debit,\n",
    "                            \"RMSE\": scores_rmse[\"RMSE\"],\n",
    "                            \"MAE\": scores_mae[\"MAE\"],\n",
    "                            \"R2\": scores_r2[\"R2\"]})\n",
    "test_scores.to_csv(\"../Data/GAMRandomForestAR/Test_scores.csv\",\n",
    "                   index = False)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a16aa-a85d-4168-8ce9-e0fa3d6c4984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
